# ğŸ“Š `create_faiss_db.py` ì½”ë“œ ë¶„ì„

## ğŸ¯ ì „ì²´ êµ¬ì¡° (5ë‹¨ê³„)

```
[1/5] Bedrock ì´ˆê¸°í™” â†’ [2/5] CSV ì½ê¸° â†’ [3/5] ë°°ì¹˜ ì²˜ë¦¬ â†’ [4/5] ë³‘í•© â†’ [5/5] í…ŒìŠ¤íŠ¸
```

---

## ğŸ“ ë‹¨ê³„ë³„ ìƒì„¸ ë¶„ì„

### **[1/5] Bedrock ì„ë² ë”© ì´ˆê¸°í™”** (27-36ì¤„)

```python
embeddings = BedrockEmbeddings(
    client=boto3.client(
        service_name="bedrock-runtime",
        region_name=os.getenv("AWS_REGION")
    ),
    model_id="amazon.titan-embed-text-v1"
)
```

**ëª©ì :**
- AWS Bedrockì˜ Titan ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
- í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì—”ì§„ ì¤€ë¹„

**ì¤‘ìš” í¬ì¸íŠ¸:**
- `.env` íŒŒì¼ì—ì„œ `AWS_REGION` ê°€ì ¸ì˜´
- `amazon.titan-embed-text-v1` ëª¨ë¸ ì‚¬ìš©

---

### **[2/5] CSV ë°ì´í„° ì½ê¸°** (38-77ì¤„)

```python
for idx, row in enumerate(reader):
    description = row.get('ì„¤ëª…', '')
    if not description.strip():
        description = f"{row.get('ëª©ë¡ëª…', '')} {row.get('í‚¤ì›Œë“œ', '')}"
```

**í•µì‹¬ ì „ëµ:**
- âœ… **ì„¤ëª… í•„ë“œë§Œ ì„ë² ë”©** (`page_content`)
- âœ… **ë‚˜ë¨¸ì§€ëŠ” ë©”íƒ€ë°ì´í„°** ì €ì¥ (ëª©ë¡ëª…, ì œê³µê¸°ê´€, URL ë“±)

**ì™œ ì´ë ‡ê²Œ?**
1. ì„¤ëª…ì´ ê²€ìƒ‰ì— ê°€ì¥ ì¤‘ìš”
2. ë©”íƒ€ë°ì´í„°ëŠ” ì„ë² ë”© ì•ˆ í•´ë„ ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ ê°€ëŠ¥
3. API í˜¸ì¶œ íš¨ìœ¨ì„± â†‘

**Document êµ¬ì¡°:**
```python
Document(
    page_content="ë°ì´í„°ì…‹ ì„¤ëª…...",  # ì„ë² ë”©ë¨
    metadata={
        "ëª©ë¡ëª…": "...",
        "ì œê³µê¸°ê´€": "...",
        "URL": "...",
        # ... 12ê°œ í•„ë“œ
    }
)
```

---

### **[3/5] ë°°ì¹˜ ì²˜ë¦¬** (79-116ì¤„)

```python
BATCH_SIZE = 100  # 100ê°œì”© ì²˜ë¦¬
total_batches = 32  # 3,143ê°œ â†’ 32ê°œ ë°°ì¹˜

for batch_idx in range(total_batches):
    batch_docs = documents[start_idx:end_idx]
    
    # ë°°ì¹˜ë³„ FAISS DB ìƒì„±
    batch_db = FAISS.from_documents(
        documents=batch_docs,
        embedding=embeddings
    )
    
    # ì„ì‹œ ì €ì¥
    batch_db.save_local(f"temp_batches/batch_{batch_idx}")
```

**ë°°ì¹˜ ì²˜ë¦¬ ì´ìœ :**
1. **ë©”ëª¨ë¦¬ íš¨ìœ¨**: í•œ ë²ˆì— ì „ì²´ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥
2. **ì•ˆì •ì„±**: ì¤‘ê°„ì— ì‹¤íŒ¨í•´ë„ ì´ë¯¸ ì²˜ë¦¬ëœ ë°°ì¹˜ëŠ” ì €ì¥ë¨
3. **ì§„í–‰ ìƒí™© í™•ì¸**: ê° ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ë¥  í‘œì‹œ

**ì €ì¥ ìœ„ì¹˜:**
```
DevOps/rag/data/temp_batches/
â”œâ”€â”€ batch_0/
â”œâ”€â”€ batch_1/
â”œâ”€â”€ ...
â””â”€â”€ batch_31/
```

---

### **[4/5] ë°°ì¹˜ ë³‘í•©** (118-159ì¤„)

```python
# ì²« ë²ˆì§¸ ë°°ì¹˜ ë¡œë“œ
final_db = FAISS.load_local(batch_db_paths[0], embeddings)

# ë‚˜ë¨¸ì§€ ë°°ì¹˜ ë³‘í•©
for batch_path in batch_db_paths[1:]:
    batch_db = FAISS.load_local(batch_path, embeddings)
    final_db.merge_from(batch_db)  # í•µì‹¬!
```

**`merge_from()` ë©”ì„œë“œ:**
- FAISSì˜ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ë³‘í•©
- ëª¨ë“  Documentë¥¼ í•˜ë‚˜ì˜ DBë¡œ í†µí•©

**ìµœì¢… ì €ì¥:**
```python
final_db.save_local("DevOps/rag/data/faiss_dataset_db")
```

**ì •ë¦¬:**
```python
shutil.rmtree(temp_dir)  # ì„ì‹œ ë°°ì¹˜ í´ë” ì‚­ì œ
```

---

### **[5/5] í…ŒìŠ¤íŠ¸ ê²€ìƒ‰** (161-182ì¤„)

```python
test_query = "ì˜ë£Œ ë°ì´í„°"
test_results = final_db.similarity_search(test_query, k=5)

for doc in test_results:
    print(doc.metadata.get('ëª©ë¡ëª…'))
    print(doc.metadata.get('ì œê³µê¸°ê´€'))
```

**ê²€ì¦ í•­ëª©:**
- âœ… DB ë¡œë“œ ì„±ê³µ
- âœ… ê²€ìƒ‰ ê¸°ëŠ¥ ì‘ë™
- âœ… ë©”íƒ€ë°ì´í„° ì •ìƒ ë°˜í™˜

---

## ğŸ’¡ í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸

### 1ï¸âƒ£ **íš¨ìœ¨ì  ì„ë² ë”©**
```
ì„¤ëª… í•„ë“œë§Œ ì„ë² ë”© â†’ API í˜¸ì¶œ ìµœì†Œí™”
ë‚˜ë¨¸ì§€ëŠ” ë©”íƒ€ë°ì´í„° â†’ ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨
```

### 2ï¸âƒ£ **ë°°ì¹˜ ì²˜ë¦¬ ì „ëµ**
```
3,143ê°œ â†’ 32ê°œ ë°°ì¹˜(100ê°œì”©)
ê° ë°°ì¹˜ ì €ì¥ â†’ ì•ˆì •ì„± â†‘
ëª¨ë‘ ë³‘í•© â†’ í•˜ë‚˜ì˜ DB
```

### 3ï¸âƒ£ **FAISS íŠ¹ì§•**
- í˜ì´ìŠ¤ë¶ì´ ê°œë°œí•œ ê³ ì† ìœ ì‚¬ë„ ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬
- ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰
- `similarity_search(query, k=5)` â†’ ìƒìœ„ 5ê°œ ë°˜í™˜

---

## ğŸ¯ ì‹¤í–‰ íë¦„ ìš”ì•½

```
CSV ì½ê¸° (3,143í–‰)
    â†“
Document ìƒì„± (ì„¤ëª… + ë©”íƒ€ë°ì´í„°)
    â†“
ë°°ì¹˜ 1~32 (100ê°œì”©)
    â†“
ê° ë°°ì¹˜ ì„ë² ë”© & ì €ì¥
    â†“
32ê°œ ë°°ì¹˜ ë³‘í•©
    â†“
ìµœì¢… FAISS DB ì €ì¥
    â†“
í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
```

---

## ğŸ“Œ ì£¼ìš” ë³€ìˆ˜

| ë³€ìˆ˜ | ê°’ | ì„¤ëª… |
|------|-----|------|
| `BATCH_SIZE` | 100 | ë°°ì¹˜ë‹¹ Document ìˆ˜ |
| `total_batches` | 32 | ì´ ë°°ì¹˜ ê°œìˆ˜ |
| `csv_file_path` | `split_data_01.csv` | ì…ë ¥ CSV |
| `final_save_path` | `faiss_dataset_db` | ìµœì¢… ì €ì¥ ìœ„ì¹˜ |
| `temp_dir` | `temp_batches/` | ì„ì‹œ ì €ì¥ í´ë” |

---

## ğŸ”‘ í•µì‹¬ ì½”ë“œ ìŠ¤ë‹ˆí«

### Bedrock ì´ˆê¸°í™”
```python
embeddings = BedrockEmbeddings(
    client=boto3.client(
        service_name="bedrock-runtime",
        region_name=os.getenv("AWS_REGION")
    ),
    model_id="amazon.titan-embed-text-v1"
)
```

### Document ìƒì„±
```python
doc = Document(
    page_content=description,  # ì„¤ëª…ë§Œ ì„ë² ë”©
    metadata={
        "ëª©ë¡ëª…": row.get('ëª©ë¡ëª…'),
        "ì œê³µê¸°ê´€": row.get('ì œê³µê¸°ê´€'),
        "URL": row.get('ëª©ë¡ URL'),
        # ... ê¸°íƒ€ í•„ë“œ
    }
)
```

### ë°°ì¹˜ ì²˜ë¦¬
```python
for batch_idx in range(total_batches):
    batch_docs = documents[start_idx:end_idx]
    batch_db = FAISS.from_documents(batch_docs, embeddings)
    batch_db.save_local(f"{temp_dir}/batch_{batch_idx}")
```

### ë³‘í•©
```python
final_db = FAISS.load_local(batch_db_paths[0], embeddings)
for batch_path in batch_db_paths[1:]:
    batch_db = FAISS.load_local(batch_path, embeddings)
    final_db.merge_from(batch_db)
```

### ê²€ìƒ‰
```python
results = final_db.similarity_search(query, k=5)
for doc in results:
    print(doc.metadata.get('ëª©ë¡ëª…'))
    print(doc.page_content)
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **FAISS**: https://github.com/facebookresearch/faiss
- **LangChain**: https://python.langchain.com/
- **AWS Bedrock**: https://aws.amazon.com/bedrock/
