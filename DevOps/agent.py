import os
import pandas as pd
import operator
from typing import TypedDict, Annotated, List, Union
from dotenv import load_dotenv

# LLMì€ OpenAIë¥¼ ì‚¬ìš©í•˜ê³ , ì„ë² ë”©ì€ ê¸°ì¡´ Googleì„ ìœ ì§€í•˜ê±°ë‚˜ OpenAIë¡œ êµì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
# ì—¬ê¸°ì„œëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ LLMì„ OpenAIë¡œ ì „í™˜í•©ë‹ˆë‹¤.
from langchain_openai import ChatOpenAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(__file__), "..", ".env"))

# 1. API í‚¤ ì„¤ì •
google_api_key = os.getenv("GOOGLE_API_KEY")
openai_api_key = os.getenv("OPENAI_API_KEY")

# ì„ë² ë”© ëª¨ë¸ (ê¸°ì¡´ êµ¬ê¸€ ì¸ë±ìŠ¤ê°€ ìˆë‹¤ë©´ ìœ ì§€, ì—†ë‹¤ë©´ ìƒˆë¡œ ìƒì„±)
# ë§Œì•½ ì„ë² ë”© í• ë‹¹ëŸ‰ë„ ë¬¸ì œë¼ë©´ OpenAIEmbeddingsë¡œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001", 
    google_api_key=google_api_key
)

# [ë³€ê²½] OpenAI ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(
    model="gpt-4o", # ë˜ëŠ” "gpt-4-turbo"
    openai_api_key=openai_api_key,
    temperature=0,
)

INDEX_PATH = "faiss_index"
CSV_PATH = r"c:\Users\Jang_home\Desktop\git tool\DatasetExplorerAI\DevOps\etl\data\ê³µê³µë°ì´í„°í™œìš©ì§€ì›ì„¼í„°_ê³µê³µë°ì´í„°í¬í„¸ ëª©ë¡ê°œë°©í˜„í™©_20251130.csv"

# 2. 'ì´ˆê³ ì† ë„ì„œê´€' ë¡œì§ (íŒŒì¼ ë¡œë“œ ë° í´ë°±)
def setup_library():
    """
    ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì—†ì„ ê²½ìš° í‚¤ì›Œë“œ ê²€ìƒ‰(Pandas)ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    ì¸ë±ìŠ¤ ìƒì„±ì€ 'ingest_data.py'ë¥¼ í†µí•´ ë³„ë„ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    df = pd.read_csv(CSV_PATH, encoding='utf-8', low_memory=False)
    df['search_text'] = df.apply(lambda x: 
        f"ë°ì´í„°ì…‹ëª…: {str(x['ëª©ë¡ëª…'])}, ì„¤ëª…: {str(x['ì„¤ëª…'])}, í‚¤ì›Œë“œ: {str(x['í‚¤ì›Œë“œ'])}, ì œê³µê¸°ê´€: {str(x['ì œê³µê¸°ê´€'])}", 
        axis=1
    ).fillna("ì •ë³´ ì—†ìŒ")
    
    vector_db = None
    
    # 1. íŒŒì¼ì—ì„œ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
    if os.path.exists(INDEX_PATH):
        try:
            print(f"--- [ë„ì„œê´€] ë¡œì»¬ ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘ ({INDEX_PATH}) ---")
            vector_db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
            print("âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ!")
        except Exception as e:
            print(f"âš ï¸ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print(f"ğŸ’¡ [ì•Œë¦¼] ì €ì¥ëœ ì¸ë±ìŠ¤ í´ë”('{INDEX_PATH}')ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¡ 'python ingest_data.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ë¨¼ì € ìƒì„±í•˜ë©´ í›¨ì”¬ ì •í™•í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        print(f"ğŸ’¡ í˜„ì¬ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    
    return vector_db, df

vector_db, full_df = setup_library()

# 3. ìƒíƒœ ë° ë…¸ë“œ ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    found_info: str

def search_node(state: AgentState):
    print("\n--- [ì¡°ì‚¬íŒ€] ë°ì´í„°ì…‹ ì°¾ëŠ” ì¤‘ ---")
    query = state["messages"][-1].content
    
    if vector_db:
        try:
            docs = vector_db.similarity_search(query, k=3)
            info = "\n\n".join([doc.page_content for doc in docs])
            print("- ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return {"found_info": info}
        except:
            pass
            
    mask = full_df['search_text'].str.contains(query, case=False, na=False)
    matched = full_df[mask].head(3)
    
    if not matched.empty:
        info = "\n\n".join(matched['search_text'].tolist())
        print(f"- í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ {len(matched)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    else:
        info = "ê´€ë ¨ëœ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    return {"found_info": info}

def analyze_node(state: AgentState):
    print("--- [ì—ì´ì „íŠ¸] ì¶”ì²œ ë‹µë³€ ìƒì„± ì¤‘ (OpenAI ì‚¬ìš©) ---")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ 'ë°ì´í„°ì…‹ íƒí—˜ê°€ ì—ì´ì „íŠ¸'ì…ë‹ˆë‹¤. 
        ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ ë°ì´í„°ì…‹ì„ ì¶”ì²œí•˜ì„¸ìš”.
        ê²€ìƒ‰ëœ ì •ë³´ê°€ ë¶€ì¡±í•˜ë”ë¼ë„ ì•„ëŠ” ë²”ìœ„ ë‚´ì—ì„œ ìµœì„ ì„ ë‹¤í•´ ê°€ì´ë“œí•˜ì„¸ìš”.
        """),
        ("placeholder", "{messages}")
    ])
    
    chain = prompt | llm
    response = chain.invoke({
        "messages": state["messages"],
        "found_info": state["found_info"]
    })
    
    return {"messages": [response]}

# 4. ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(AgentState)
workflow.add_node("searcher", search_node)
workflow.add_node("analyzer", analyze_node)
workflow.set_entry_point("searcher")
workflow.add_edge("searcher", "analyzer")
workflow.add_edge("analyzer", END)
app = workflow.compile()

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    test_q = "ë‚ ì”¨ë‚˜ ë¯¸ì„¸ë¨¼ì§€ ê´€ë ¨ ë°ì´í„°ì…‹ì´ ë­ì•¼?"
    print(f"ğŸš€ ìš”ì²­: {test_q}")
    
    inputs = {"messages": [HumanMessage(content=test_q)]}
    for output in app.stream(inputs):
        for key, value in output.items():
            if key == "analyzer":
                print(f"\nâœ… ì—ì´ì „íŠ¸ ì¶”ì²œ (OpenAI):\n{value['messages'][-1].content}")
