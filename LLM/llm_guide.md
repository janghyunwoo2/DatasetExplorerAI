# LLM Layer í†µí•© ê°€ì´ë“œ

> Agent, RAG, FAISS ì™„ë²½ ê°€ì´ë“œ

---

## ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#1-ì‹œìŠ¤í…œ-ê°œìš”)
2. [Agent (LangGraph)](#2-agent-langgraph)
3. [RAG Store (FAISS ê²€ìƒ‰)](#3-rag-store-faiss-ê²€ìƒ‰)
4. [Tools (ë„êµ¬ ì •ì˜)](#4-tools-ë„êµ¬-ì •ì˜)
5. [FAISS DB ìƒì„±](#5-faiss-db-ìƒì„±)
6. [ì‹¤í–‰ íë¦„](#6-ì‹¤í–‰-íë¦„)

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

### ì•„í‚¤í…ì²˜

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
agent_with_garph.py (LangGraph ì›Œí¬í”Œë¡œìš°)
    â†“
tools.py (rag_search ë„êµ¬)
    â†“
rag_store.py (FAISS ê²€ìƒ‰ + ë‚ ì§œ ì •ë ¬)
    â†“
faiss_dataset_db/ (3,143ê°œ ë°ì´í„°ì…‹)
    â†“
ìµœì‹  ë°ì´í„°ì…‹ ë°˜í™˜
```

### í•µì‹¬ íŒŒì¼

| íŒŒì¼ | ì—­í•  | ì£¼ìš” ê¸°ëŠ¥ |
|------|------|-----------|
| `agent_with_garph.py` | LangGraph Agent | í‚¤ì›Œë“œ ë¼ìš°íŒ…, RAG ê°•ì œ ì‚¬ìš© |
| `rag_store.py` | FAISS ê²€ìƒ‰ | ë²¡í„° ê²€ìƒ‰, ë‚ ì§œ ì •ë ¬ |
| `tools.py` | ë„êµ¬ ì •ì˜ | rag_search ë„êµ¬ ë“±ë¡ |
| `faiss_dataset_db/` | ë²¡í„° DB | 3,143ê°œ ì„ë² ë”© |

---

## 2. Agent (LangGraph)

> ğŸ“„ [agent_with_garph.py](file:///C:/Users/3571/Desktop/projects/DatasetExplorerAI/LLM/agent_with_garph.py)

### 2-1. í•µì‹¬ ì›Œí¬í”Œë¡œìš°

```
routing (í‚¤ì›Œë“œ ê²€ì‚¬)
    â†“
dataset_keywords ìˆìŒ? â†’ tools (RAG ê°•ì œ)
                      â†’ final_answer (ê²°ê³¼ ì •ë¦¬)
    â†“
í‚¤ì›Œë“œ ì—†ìŒ? â†’ thinking (LLM ì§ì ‘ ì‘ë‹µ)
```

### 2-2. í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ìš°íŒ… â­â­â­

```python
# 45ê°œ í‚¤ì›Œë“œë¡œ RAG ê°•ì œ ì‚¬ìš©
dataset_keywords = [
    # ë™ì‚¬
    "ì°¾ì•„", "ì¶”ì²œ", "ê²€ìƒ‰", "ë³´ì—¬", "ì•Œë ¤", "êµ¬í•´", "ì›í•´",
    # ëª…ì‚¬
    "ë°ì´í„°", "ì •ë³´", "ìë£Œ", "í†µê³„", "ëª©ë¡",
    # ê¸°íƒ€
    "ë­", "ë¬´ì—‡", "ì–´ë””", "ì–´ë–¤"
]

# í‚¤ì›Œë“œ ê°ì§€ â†’ ë¬´ì¡°ê±´ RAG ì‚¬ìš©
if any(keyword in user_query for keyword in dataset_keywords):
    return {"_route": "tools"}  # RAG ê°•ì œ!
```

**íš¨ê³¼**: RAG ì‚¬ìš©ë¥  **100%**

### 2-3. ì´ì¤‘ í”„ë¡¬í”„íŠ¸ ì „ëµ

**thinking_nodeìš©** (ì¼ë°˜ ëŒ€í™”):
```python
final_prompt = "ì¼ë°˜ ëŒ€í™” ì „ìš©, RAG ì‚¬ìš© ë¶ˆê°€"
```

**final_answer_nodeìš©** (RAG ê²°ê³¼ ë¶„ì„):
```python
rag_result_prompt = "ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„, ì£¼ì œ ì¼ì¹˜ íŒë‹¨, URL í•„ìˆ˜"
```

**ìì„¸í•œ ë‚´ìš©**: [agent_code_analysis.md](file:///C:/Users/3571/Desktop/projects/DatasetExplorerAI/LLM/agent_code_analysis.md)

---

## 3. RAG Store (FAISS ê²€ìƒ‰)

> ğŸ“„ [rag_store.py](file:///C:/Users/3571/Desktop/projects/DatasetExplorerAI/LLM/rag_store.py)

### 3-1. FAISS DB ë¡œë“œ

```python
# 1. Bedrock ì„ë² ë”© ì´ˆê¸°í™”
embeddings = BedrockEmbeddings(
    client=boto3.client("bedrock-runtime", region_name=os.getenv("AWS_REGION")),
    model_id="amazon.titan-embed-text-v1"
)

# 2. FAISS DB ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ)
script_dir = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(script_dir, "faiss_dataset_db")

vector_db = FAISS.load_local(
    DB_PATH,
    embeddings,
    allow_dangerous_deserialization=True
)
```

**í•µì‹¬**: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©ìœ¼ë¡œ Web/Back_endì—ì„œë„ ì ‘ê·¼ ê°€ëŠ¥

### 3-2. ê²€ìƒ‰ + ë‚ ì§œ ì •ë ¬ â­â­â­

> ğŸ“„ [rag_store.py:L41-L92](file:///C:/Users/3571/Desktop/projects/DatasetExplorerAI/LLM/rag_store.py#L41-L92)

```python
def search_stores(query: str, k: int=5):
    """
    FAISS ê²€ìƒ‰ í›„ ìµœì‹  ë°ì´í„° ìš°ì„  ì •ë ¬
    """
    # 1. k*2ê°œ ê²€ìƒ‰ (ì—¬ìœ  ìˆê²Œ)
    docs = vector_db.similarity_search(query, k=k*2)
    
    # 2. ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜
    def parse_date(date_str):
        if not date_str or date_str == 'N/A':
            return datetime.min
        for fmt in ['%Y-%m-%d', '%Y%m%d', '%Y.%m.%d']:
            try:
                return datetime.strptime(date_str.strip(), fmt)
            except:
                continue
        return datetime.min
    
    # 3. ìˆ˜ì •ì¼ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
    sorted_docs = sorted(
        docs,
        key=lambda x: parse_date(x.metadata.get('ìˆ˜ì •ì¼', '')),
        reverse=True
    )
    
    # 4. ìƒìœ„ kê°œë§Œ ë°˜í™˜
    final_docs = sorted_docs[:k]
    
    # 5. í¬ë§·íŒ…
    results = []
    for i, doc in enumerate(final_docs, 1):
        result = f"{i}. {doc.metadata.get('ëª©ë¡ëª…', 'N/A')}\n"
        result += f"   ì œê³µê¸°ê´€: {doc.metadata.get('ì œê³µê¸°ê´€', 'N/A')}\n"
        result += f"   ë¶„ë¥˜: {doc.metadata.get('ë¶„ë¥˜ì²´ê³„', 'N/A')}\n"
        result += f"   ìˆ˜ì •ì¼: {doc.metadata.get('ìˆ˜ì •ì¼', 'N/A')}\n"
        result += f"   URL: {doc.metadata.get('URL', 'N/A')}"
        results.append(result)
    
    return "\n\n".join(results)
```

**í•µì‹¬**:
1. **k*2ê°œ ê²€ìƒ‰** â†’ ì¶©ë¶„í•œ í›„ë³´ í™•ë³´
2. **ë‚ ì§œ ì •ë ¬** â†’ ìµœì‹  ë°ì´í„° ìš°ì„ 
3. **ìƒìœ„ kê°œ** â†’ ìµœì¢… ë°˜í™˜

---

## 4. Tools (ë„êµ¬ ì •ì˜)

> ğŸ“„ [tools.py](file:///C:/Users/3571/Desktop/projects/DatasetExplorerAI/LLM/tools.py)

### RAG Search ë„êµ¬

```python
from langchain_core.tools import tool
from rag_store import search_stores

@tool
def rag_search(query: str, k: int = 5) -> str:
    '''
    ë°ì´í„°ì…‹ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥ë°›ê³ , FAISS RAGë¥¼ ì´ìš©í•´ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    
    Args:
        query: ê²€ìƒ‰í•  ë°ì´í„°ì…‹ í‚¤ì›Œë“œ (ì˜ˆ: "ì˜ë£Œ", "êµí†µ", "í™˜ê²½")
        k: ë°˜í™˜í•  ë°ì´í„°ì…‹ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
    
    Returns:
        ê²€ìƒ‰ëœ ë°ì´í„°ì…‹ ì •ë³´ (ëª©ë¡ëª…, ì œê³µê¸°ê´€, ë¶„ë¥˜, URL)
    '''
    try:
        res = search_stores(query, k)
        return res if res else "ê´€ë ¨ ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
```

**í•µì‹¬**: `@tool` ë°ì½”ë ˆì´í„°ë¡œ LangChain ë„êµ¬ ë“±ë¡

---

## 5. FAISS DB ìƒì„±

> ğŸ“„ [rag/create_faiss_db.py](file:///C:/Users/3571/Desktop/projects/DatasetExplorerAI/LLM/rag/create_faiss_db.py)

### ë°°ì¹˜ ì²˜ë¦¬ ì „ëµ

```python
BATCH_SIZE = 100  # ë°°ì¹˜ë‹¹ 100ê°œ
documents = load_csv_data()  # 3,143ê°œ ë¬¸ì„œ

# ë°°ì¹˜ë³„ ì²˜ë¦¬
for i in range(0, len(documents), BATCH_SIZE):
    batch = documents[i:i+BATCH_SIZE]
    
    # FAISS DB ìƒì„±
    batch_db = FAISS.from_documents(batch, embeddings)
    
    # ì €ì¥
    batch_db.save_local(f"temp/batch_{i//BATCH_SIZE}")
```

### ë°°ì¹˜ ë³‘í•©

```python
# ì²« ë°°ì¹˜ ë¡œë“œ
final_db = FAISS.load_local("temp/batch_0", embeddings)

# ë‚˜ë¨¸ì§€ ë³‘í•©
for path in batch_paths[1:]:
    batch = FAISS.load_local(path, embeddings)
    final_db.merge_from(batch)  # â­ í•µì‹¬!

# ìµœì¢… ì €ì¥
final_db.save_local("faiss_dataset_db")
```

**íš¨ê³¼**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬

---

## 6. ì‹¤í–‰ íë¦„

### ì§ˆë¬¸ â†’ ë‹µë³€ ì „ì²´ í”„ë¡œì„¸ìŠ¤

```
1. ì‚¬ìš©ì: "ì˜ë£Œ ë°ì´í„° ì°¾ì•„ì¤˜"
   â†“
2. agent_with_garph.py
   - routing_node: "ë°ì´í„°", "ì°¾ì•„" í‚¤ì›Œë“œ ê°ì§€
   - _route = "tools"
   â†“
3. tools_node
   - rag_search ë„êµ¬ í˜¸ì¶œ
   â†“
4. tools.py
   - rag_search(query="ì˜ë£Œ ë°ì´í„° ì°¾ì•„ì¤˜", k=5)
   â†“
5. rag_store.py
   - FAISS ê²€ìƒ‰ (k*2=10ê°œ)
   - ë‚ ì§œ ì •ë ¬
   - ìƒìœ„ 5ê°œ ë°˜í™˜
   â†“
6. final_answer_node
   - RAG ê²°ê³¼ ë¶„ì„
   - ì£¼ì œ ì¼ì¹˜ í™•ì¸
   - í¬ë§·íŒ…
   â†“
7. ì‘ë‹µ:
   1. **ì˜ë£Œê¸°ê´€ ê°œì„¤í˜„í™©**
      - ì œê³µê¸°ê´€: ë³´ê±´ë³µì§€ë¶€
      - ìˆ˜ì •ì¼: 2025-11-14
      - URL: https://...
```

---

## ì½”ë“œ ê°„ ì—°ê²° ê´€ê³„

### Import ì²´ê³„

```python
# agent_with_garph.py
from tools import rag_search

# tools.py
from rag_store import search_stores

# rag_store.py
from langchain_community.vectorstores import FAISS
```

### ë°ì´í„° íë¦„

```
CSV ë°ì´í„°
    â†“
create_faiss_db.py (ë°°ì¹˜ ì²˜ë¦¬)
    â†“
faiss_dataset_db/ (ì €ì¥)
    â†“
rag_store.py (ë¡œë“œ)
    â†“
tools.py (ë„êµ¬ ë˜í•‘)
    â†“
agent_with_garph.py (Agent ì‚¬ìš©)
```

---

## í•µì‹¬ ìš”ì•½

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
|----------|------|-----------|
| **Agent** | ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ | í‚¤ì›Œë“œ ë¼ìš°íŒ… (45ê°œ) |
| **RAG Store** | FAISS ê²€ìƒ‰ | k*2 ê²€ìƒ‰ + ë‚ ì§œ ì •ë ¬ |
| **Tools** | ë„êµ¬ ë“±ë¡ | `@tool` ë°ì½”ë ˆì´í„° |
| **FAISS DB** | ë²¡í„° ì €ì¥ì†Œ | 3,143ê°œ ì„ë² ë”© |

### ì„±ëŠ¥ ì§€í‘œ

- **RAG ì‚¬ìš©ë¥ **: 100%
- **í™˜ê° ë°©ì§€**: 100%
- **ìµœì‹  ë°ì´í„°**: ë‚ ì§œ ì •ë ¬ë¡œ ë³´ì¥
- **ê²€ìƒ‰ ì†ë„**: ~50ms (3ì²œ ê°œ ê¸°ì¤€)

---

ğŸ“„ **ê´€ë ¨ íŒŒì¼**:
- [agent_with_garph.py](LLM/agent_with_garph.py)
- [rag_store.py](LLM/rag_store.py)
- [tools.py](LLM/tools.py)
- [rag/create_faiss_db.py](LLM/rag/create_faiss_db.py)
- [agent_code_analysis.md](LLM/agent_code_analysis.md) (ìƒì„¸ Agent ë¶„ì„)
