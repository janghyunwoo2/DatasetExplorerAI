import boto3
import json
import os
from dotenv import load_dotenv

load_dotenv()

bedrock_client = boto3.client(
    service_name="bedrock-runtime",
    region_name=os.getenv("AWS_REGION"),
    aws_session_token=os.getenv("AWS_BEARER_TOKEN_BEDROCK")
)

def ask_aws_bedrock_claude_mcp_style(user_query):
    model_id = "anthropic.claude-3-5-sonnet-20240620-v1:0"
    
    # 1. ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        {
            "role": "user",
            "content": [{"text": user_query}]
        }
    ]

    try:
        # 2. Converse API í˜¸ì¶œ
        response = bedrock_client.converse(
            modelId=model_id,
            messages=messages,
            inferenceConfig={
                "maxTokens": 1024,
                "temperature": 0.5,
            }
        )

        # 3. ë‹µë³€ ì¶”ì¶œ
        response_text = response['output']['message']['content'][0]['text']
        return response_text

    except Exception as e:
        return f"âŒ ì—ëŸ¬ ë°œìƒ: {e}"

# ---------------------------------------------------------
# [ìˆ˜ì •ëœ ë¶€ë¶„] ë”°ë¦‰ì´ ë”ë¯¸ ë°ì´í„°
# ---------------------------------------------------------
mock_chat = "ì„œìš¸ì‹œ ë”°ë¦‰ì´ ëŒ€ì—¬ì†Œ ìœ„ì¹˜ë‘ ì‹¤ì‹œê°„ ëŒ€ì—¬ ê°€ëŠ¥ ìˆ˜ëŸ‰ ë°ì´í„°ë¥¼ APIë¡œ ë°›ê³  ì‹¶ì–´. ì–´ë–¤ ë°ì´í„°ì…‹ì„ ê²€ìƒ‰í•´ì•¼ ë¼?"

print(f"ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸(ë”ë¯¸): {mock_chat}")
print("ğŸ¤– Claude ë¶„ì„ ì¤‘ (ë”°ë¦‰ì´ íƒìƒ‰)...")

answer = ask_aws_bedrock_claude_mcp_style(mock_chat)

print("-" * 30)
print(f"âœ… AI ë‹µë³€:\n{answer}")